---
title: "White Wine Model"
author: "Stephen Whetzel"
date: "8/10/2021"
output: html_document
---

```{r setup, include=FALSE}

library(tidyverse)
library(leaps)
library(caret)
library(car)
# library(faraway)


Data = read.csv('wineQualityWhites.csv')
Data$X <- NULL
head(Data,10)

##set the random number generator so same results can ##be reproduced
set.seed(1)
##choose the observations to be in the training set.
##I am splitting the data set into halves 
samplewhite<-sample.int(nrow(Data), floor(.80*nrow(Data)), replace = F) 
train<-Data[samplewhite, ] ##training data
test<-Data[-samplewhite, ] ##test data

```

Using a forward step-wise function to choose a model. 

```{r}

regnull <- lm(quality~1, data=train)
regfull <- lm(quality~., data=train)

step(regnull, scope=list(lower=regnull, upper=regfull), direction="forward")

```


```{r}

result_forw <- lm(formula = quality ~ alcohol + volatile.acidity + residual.sugar + 
    density + sulphates + pH + free.sulfur.dioxide + fixed.acidity, 
    data = train)

summary(result_forw)

```

.2813 adjusted R^2 isn't a great initial fit, but it's the best we have apparently. 

Trying a backwards step function next. 

```{r}

step(regfull, scope=list(lower=regnull, upper=regfull), direction="backward")


```
The backwards and forwards methods produce the same exact model. Next we'll try a stepwise function.

```{r}

step(regnull, scope=list(lower=regnull, upper=regfull), direction="both")


```
All three methods agree that the best model takes in all predictors except for citric acid, chlorides and total sulfur dioxide when determining white wine quality. 

Taking out chlorides and total sulfur dioxide makes sense given the lack of linearity within the EDA boxplot, but citric acid doesn't make as much sense to take out. I'm going to try a stepwise function that starts with a model with just citric acid and see if it ends up taking it out and then compare the adjusted r squared values. 

```{r}

regcitric <- lm(quality~citric.acid, data=train)
step(regcitric, scope=list(lower=regnull, upper=regfull), direction="both")


```

Ended up taking out citric acid anyway. I'm going to look at a summary of the model but adding in citric acid and compare the adjusted r squared values. 

```{r}

result_citric <- lm(formula = quality ~ alcohol + volatile.acidity + residual.sugar + 
    density + sulphates + pH + free.sulfur.dioxide + fixed.acidity + citric.acid, 
    data = train)

summary(result_citric)
summary(result_forw)

```

The model without citric acid actually does slightly worse than the original model. Good evidence for leaving that predictor out of the model. It doesn't significantly affect the adj r squared and we can make a marginally simpler model without it. 

let's run a Partial F test to make sure that it is okay to drop the 3 predictors dropped in the above model, chlorides, total sulfur dioxide, and citric acid

```{r}

anova(result_forw, regfull)


```

The result of the test is a F statistic of 0.68491 and a p value of 0.7526. Our null hypothesis is that the coefficients for chlorides, total sulfur dioxide, and citric acid are all equal to zero. We don't have nearly enough evidence to reject this hypothesis and so we drop the four predictors and opt for the simpler model. 

Next we'll turn to diagnosing multi-collinearity in the data by calculating the VIF for each predictor still in the model. 
```{r}

vif(result_forw)

```

```{r}

cor(Data)

```

Density has a very high VIF of 24.322503, much higher than the normal threshold of 10. As such we want to consider getting rid of a predictor correlated with this one, probably residual sugar since it has the highest correlation with density.



```{r}

reduced_forw_density <- lm(formula = quality ~ alcohol + volatile.acidity + density + sulphates + pH + free.sulfur.dioxide + fixed.acidity, data = train)

summary(reduced_forw_density)

vif(reduced_forw_density)

```
Our p-value for residual sugar doesn't support getting rid of this variable, but since this predictor shows a high VIF and correlation with density, our highest VIF value predictor, we chose to drop the variable so that our model would be useful for exploring the relationship between the predictors and the response. Running a vif analysis on the further reduced model shows that removing this variable takes a good deal of multicollinearity out of the model and should improve accuracy. 



```{r}

summary(reduced_forw_density)

```

We're now seeing a high p-values for pH. This predictor may not actually be necessary for our final model. Taking it out yields an adjusted r squared value of .2598 which is actually slightly higher than the adjusted r^2 value for the last model.  

```{r}

reduced_forw3 <- lm(quality ~ alcohol + volatile.acidity + 
                      free.sulfur.dioxide + density + sulphates + fixed.acidity, data = train)

summary(reduced_forw3)

vif(reduced_forw3)

```

This final model has the formula:
$$ \hat{y} = -3.618 + 0.406x_{alcohol} - 1.985x_{volatile\ acidity} + 0.004x_{free\ sulfur\ dioxide} + 3.885x_{density} + 0.345x_{sulphates} - 0.089x_{fixed\ acidity}}$$


The final model has a adjusted r squared of 0.2598, which isn't very strong. However the strength of this model is in it's simplicity and it's lack of multicollinearity and is the best that we can do given the nature of the data. According to this model, the most important factors when predicting a wine's quality are its alcohol content, its volatile acidity, it's free sulfur dioxide, its density, its sulphates, and its fixed acidity. alcohol, free sulfur dioxide, density and sulphates are all directly related to quality and will increase the prediction of quality when increased. Volatile acidity and fixed acidity on the other hand are indirectly related to quality and an increase in these metrics will bring down the quality prediction. 

Next we get test the model on the test data and get the MSE value for some comparative analysis. 

```{r}

predswhite <- predict(reduced_forw3, newdata=test)
squared <- (test$quality-predswhite)**2
MSE_together_white <- (sum(squared))/nrow(test)
MSE_together_white

```
```{r}

df <- data.frame(reduced_forw3$residuals, reduced_forw3$fitted.values, train$quality)

ggplot(df, aes(x=reduced_forw3.fitted.values, y=reduced_forw3.residuals))+
  geom_point()


```


